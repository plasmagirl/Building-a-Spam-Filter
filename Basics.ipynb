{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Building a Spam Filter using Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this project is to build a spam filter software for SMS messages using a dataset of 5572 SMS messages that have already been categorized as spam or ham(non-spam). The dataset was obtained from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/sms+spam+collection). Our ideal spam filter will have an accuracy of greater than 80%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sms_collection = pd.read_csv('SMSSpamCollection', sep='\\t', header=None, names=['Label', 'SMS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset contains 5572 messages.\n",
      "The percentage of non-spam (ham) vs spam messages are - \n",
      "ham     0.865937\n",
      "spam    0.134063\n",
      "Name: Label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "display(sms_collection.head())\n",
    "print('The dataset contains {} messages.' .format(sms_collection.shape[0]))\n",
    "print('The percentage of non-spam (ham) vs spam messages are - ')\n",
    "print(sms_collection['Label'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We will randomly divide the dataset into training(80%) and test modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sms_collection = sms_collection.sample(random_state=1, frac=1)\n",
    "train = sms_collection.iloc[:4458]\n",
    "test = sms_collection.iloc[4458:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1078</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yep, by the pretty sculpture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4028</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yes, princess. Are you going to make me moan?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>ham</td>\n",
       "      <td>Welp apparently he retired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4642</th>\n",
       "      <td>ham</td>\n",
       "      <td>Havent.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4674</th>\n",
       "      <td>ham</td>\n",
       "      <td>I forgot 2 ask ü all smth.. There's a card on ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                                SMS\n",
       "1078   ham                       Yep, by the pretty sculpture\n",
       "4028   ham      Yes, princess. Are you going to make me moan?\n",
       "958    ham                         Welp apparently he retired\n",
       "4642   ham                                            Havent.\n",
       "4674   ham  I forgot 2 ask ü all smth.. There's a card on ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2131</th>\n",
       "      <td>ham</td>\n",
       "      <td>Later i guess. I needa do mcat study too.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3418</th>\n",
       "      <td>ham</td>\n",
       "      <td>But i haf enuff space got like 4 mb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3424</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 10 mths? Update to latest Oran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1538</th>\n",
       "      <td>ham</td>\n",
       "      <td>All sounds good. Fingers . Makes it difficult ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5393</th>\n",
       "      <td>ham</td>\n",
       "      <td>All done, all handed in. Don't know if mega sh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                                SMS\n",
       "2131   ham          Later i guess. I needa do mcat study too.\n",
       "3418   ham             But i haf enuff space got like 4 mb...\n",
       "3424  spam  Had your mobile 10 mths? Update to latest Oran...\n",
       "1538   ham  All sounds good. Fingers . Makes it difficult ...\n",
       "5393   ham  All done, all handed in. Don't know if mega sh..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train.head())\n",
    "display(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     0.86541\n",
       "spam    0.13459\n",
       "Name: Label, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ham     0.868043\n",
       "spam    0.131957\n",
       "Name: Label, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train['Label'].value_counts(normalize=True))\n",
    "display(test['Label'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and test datasets have been created with similar percentages of ham and spam labels. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will remove all the punctuations from the columns and convert all characters to lower case. This can be done on sms_collection dataframe as train and test are copies of the original df. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dataquest/system/env/python3/lib/python3.4/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/dataquest/system/env/python3/lib/python3.4/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "train['SMS'] = train['SMS'].replace(to_replace='\\W', value=' ', regex=True)\n",
    "train['SMS'] = train['SMS'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1078</th>\n",
       "      <td>ham</td>\n",
       "      <td>yep  by the pretty sculpture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4028</th>\n",
       "      <td>ham</td>\n",
       "      <td>yes  princess  are you going to make me moan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>ham</td>\n",
       "      <td>welp apparently he retired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4642</th>\n",
       "      <td>ham</td>\n",
       "      <td>havent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4674</th>\n",
       "      <td>ham</td>\n",
       "      <td>i forgot 2 ask ü all smth   there s a card on ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                                SMS\n",
       "1078   ham                       yep  by the pretty sculpture\n",
       "4028   ham      yes  princess  are you going to make me moan \n",
       "958    ham                         welp apparently he retired\n",
       "4642   ham                                            havent \n",
       "4674   ham  i forgot 2 ask ü all smth   there s a card on ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dataquest/system/env/python3/lib/python3.4/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['gosh',\n",
       " 'emerging',\n",
       " 'discussed',\n",
       " 'inches',\n",
       " 'msging',\n",
       " '09066362231',\n",
       " 'random',\n",
       " 'entropication',\n",
       " 'uh',\n",
       " 'wipe',\n",
       " 'mahfuuz',\n",
       " 'overheating',\n",
       " 'size',\n",
       " 'drms',\n",
       " 'either',\n",
       " 'interested',\n",
       " 'confirmed',\n",
       " 'woulda',\n",
       " '400thousad',\n",
       " 'befor',\n",
       " 'wap',\n",
       " 'find',\n",
       " 'vivek',\n",
       " 'comfey',\n",
       " 'route',\n",
       " 'help08718728876',\n",
       " 'kb',\n",
       " 'l8er',\n",
       " 'lanka',\n",
       " 'willing',\n",
       " 'hows',\n",
       " 'energy',\n",
       " 'lipo',\n",
       " 'ertini',\n",
       " 'cramps',\n",
       " 'misss',\n",
       " '3750',\n",
       " 'chapel',\n",
       " 'fieldof',\n",
       " 'at',\n",
       " 'page',\n",
       " '69669',\n",
       " 'lingerie',\n",
       " 'chk',\n",
       " 'torch',\n",
       " 'enemy',\n",
       " 'thankyou',\n",
       " 'bad',\n",
       " 'bangbabes',\n",
       " '09066380611',\n",
       " 'chip',\n",
       " 'shove',\n",
       " 'shop',\n",
       " 'award',\n",
       " 'know',\n",
       " 'envelope',\n",
       " 'verifying',\n",
       " '08715203652',\n",
       " 'warning',\n",
       " 'flirtparty',\n",
       " 'subscribed',\n",
       " 'grown',\n",
       " 'then',\n",
       " '5',\n",
       " 'wining',\n",
       " 'smth',\n",
       " 'faggot',\n",
       " 'promise',\n",
       " 'went',\n",
       " 'flyng',\n",
       " 'dippeditinadew',\n",
       " 'ktv',\n",
       " '09061701851',\n",
       " 'permissions',\n",
       " 'certificate',\n",
       " 'tooth',\n",
       " 'noi',\n",
       " 'mmsto',\n",
       " 'sportsx',\n",
       " 'island',\n",
       " 'cave',\n",
       " 'loans',\n",
       " 'dnot',\n",
       " 'gmw',\n",
       " 'pei',\n",
       " 'life',\n",
       " 'beauties',\n",
       " 'adress',\n",
       " 'age',\n",
       " 'jos',\n",
       " 'prayrs',\n",
       " 'crckt',\n",
       " 'rays',\n",
       " '000',\n",
       " 'especially',\n",
       " 'fake',\n",
       " 'american',\n",
       " 'warned',\n",
       " 'nb',\n",
       " 'waheed',\n",
       " 'sef',\n",
       " 'daddy',\n",
       " '8am',\n",
       " 'sk3',\n",
       " 'till',\n",
       " '1winaweek',\n",
       " 'status',\n",
       " 'anna',\n",
       " 'increase',\n",
       " 'education',\n",
       " 'pobox75ldns7',\n",
       " 'basically',\n",
       " 'hoo',\n",
       " 'dodgey',\n",
       " 'delicious',\n",
       " 'bold',\n",
       " '910',\n",
       " 'ibiza',\n",
       " 'barrel',\n",
       " 'bridal',\n",
       " 'franxx',\n",
       " 'messenger',\n",
       " 'sources',\n",
       " 'incident',\n",
       " '5249',\n",
       " 'bawling',\n",
       " 'answers',\n",
       " 'morn',\n",
       " 'lodging',\n",
       " 'indicate',\n",
       " 'e',\n",
       " 'bollox',\n",
       " 'somewhat',\n",
       " 'creativity',\n",
       " 'com1win150ppmx3age16subscription',\n",
       " 'guoyang',\n",
       " 'battery',\n",
       " 'identification',\n",
       " 'reflex',\n",
       " 'unnecessarily',\n",
       " 'ntimate',\n",
       " '09050002311',\n",
       " 'rich',\n",
       " 'wewa',\n",
       " 'kittum',\n",
       " 'realise',\n",
       " 'social',\n",
       " 'password',\n",
       " 's89',\n",
       " 'ecstacy',\n",
       " 'fromm',\n",
       " 'steed',\n",
       " 'drugs',\n",
       " 'method',\n",
       " 'whenevr',\n",
       " 'lovable',\n",
       " 'prices',\n",
       " 'allowed',\n",
       " 'cuppa',\n",
       " 'name2',\n",
       " 'jones',\n",
       " 'specify',\n",
       " 'weight',\n",
       " 'strt',\n",
       " 'area',\n",
       " 'ans',\n",
       " 'name',\n",
       " 'ello',\n",
       " 'persolvo',\n",
       " 'dedicated',\n",
       " 'roomate',\n",
       " 'lovely',\n",
       " 'adults',\n",
       " 'closes',\n",
       " 'tablet',\n",
       " 'shower',\n",
       " 'stomps',\n",
       " 'jess',\n",
       " 'destiny',\n",
       " '08715203656',\n",
       " 'mokka',\n",
       " 'rcvd',\n",
       " 'xy',\n",
       " 'ma',\n",
       " 'strewn',\n",
       " '7ws',\n",
       " 'dub',\n",
       " 'felt',\n",
       " 'tendencies',\n",
       " 'menu',\n",
       " 'father',\n",
       " 'asleep',\n",
       " 'andrews',\n",
       " 'better',\n",
       " 'plz',\n",
       " 'rings',\n",
       " 'every1',\n",
       " 'olowoyey',\n",
       " 'wc1n3xx',\n",
       " 'beer',\n",
       " 'cya',\n",
       " 'nigro',\n",
       " 'neglet',\n",
       " 'receipt',\n",
       " '08452810075over18',\n",
       " 'potter',\n",
       " 'guide',\n",
       " 'eppolum',\n",
       " 'divorce',\n",
       " 'enuff',\n",
       " 'factory',\n",
       " 'four',\n",
       " 'possibly',\n",
       " 'gona',\n",
       " 'hear',\n",
       " 'immediately',\n",
       " '542',\n",
       " 'whr',\n",
       " 'textin',\n",
       " 'gravy',\n",
       " 'mack',\n",
       " 'glands',\n",
       " 'brilliantly',\n",
       " 'decide',\n",
       " 'tmorow',\n",
       " 'dismay',\n",
       " '700',\n",
       " 'shakara',\n",
       " 'hint',\n",
       " 'cheese',\n",
       " 'dhina',\n",
       " 'crack',\n",
       " '21',\n",
       " 'tel',\n",
       " 'addie',\n",
       " 'line',\n",
       " 'haunt',\n",
       " 'aburo',\n",
       " 'go2sri',\n",
       " 'crab',\n",
       " 'oil',\n",
       " 'j',\n",
       " 'w1jhl',\n",
       " 'received',\n",
       " 'sections',\n",
       " 'conform',\n",
       " 'tarpon',\n",
       " 'tactless',\n",
       " 'unsold',\n",
       " 'six',\n",
       " 'captaining',\n",
       " 'secretly',\n",
       " 'within',\n",
       " 'used',\n",
       " 'full',\n",
       " 'into',\n",
       " 'optout',\n",
       " 'nuther',\n",
       " 'nice',\n",
       " 'citylink',\n",
       " 'banned',\n",
       " 'waht',\n",
       " 'eurodisinc',\n",
       " 'log',\n",
       " 'pest',\n",
       " 'welcomes',\n",
       " 'offer',\n",
       " 'bribe',\n",
       " '08700435505150p',\n",
       " 'gone',\n",
       " 'friendships',\n",
       " '07946746291',\n",
       " 'mca',\n",
       " 'goin',\n",
       " 'predictive',\n",
       " 'shining',\n",
       " 'work',\n",
       " 'rolled',\n",
       " 'sickness',\n",
       " 'league',\n",
       " 'financial',\n",
       " 'jerry',\n",
       " 'cn',\n",
       " 'velly',\n",
       " 'awake',\n",
       " 'monday',\n",
       " 'missunderstding',\n",
       " 'quiet',\n",
       " 'txt',\n",
       " 'castor',\n",
       " 'rtm',\n",
       " 'catches',\n",
       " 'certainly',\n",
       " 'workand',\n",
       " 'les',\n",
       " 'puzzeles',\n",
       " 'uneventful',\n",
       " 'mine',\n",
       " 'becomes',\n",
       " 'hopes',\n",
       " 'ups',\n",
       " 'correctly',\n",
       " 'lots',\n",
       " 'tonexs',\n",
       " 'umma',\n",
       " 'talks',\n",
       " 'kappa',\n",
       " 'hug',\n",
       " 'lately',\n",
       " 'wt',\n",
       " 'salmon',\n",
       " 'rewarding',\n",
       " 'goto',\n",
       " '3100',\n",
       " 'nike',\n",
       " 'odalebeku',\n",
       " 'medicine',\n",
       " 'ending',\n",
       " 'videos',\n",
       " '14',\n",
       " 'reference',\n",
       " 'smsco',\n",
       " 'remember',\n",
       " 'frnt',\n",
       " 'disconnected',\n",
       " '900',\n",
       " 'kitty',\n",
       " 'eerie',\n",
       " 'copy',\n",
       " 'finest',\n",
       " 'piss',\n",
       " 'bills',\n",
       " 'heading',\n",
       " 'bears',\n",
       " 'subscribe6gbp',\n",
       " 'buns',\n",
       " 'messed',\n",
       " 'inform',\n",
       " 'checking',\n",
       " 'getzed',\n",
       " 'txtstop',\n",
       " 'spend',\n",
       " 'somethin',\n",
       " 'home',\n",
       " 'hook',\n",
       " 'tuition',\n",
       " 'pobox202',\n",
       " 'bright',\n",
       " 'rcd',\n",
       " 'orange',\n",
       " 'brum',\n",
       " 'serving',\n",
       " 'dey',\n",
       " 'rebooting',\n",
       " 'spring',\n",
       " 'joy',\n",
       " 'drastic',\n",
       " '95',\n",
       " 'magicalsongs',\n",
       " 'mini',\n",
       " 'maangalyam',\n",
       " 'ads',\n",
       " '08712300220',\n",
       " 'cuz',\n",
       " '88800',\n",
       " 'experiment',\n",
       " 'paris',\n",
       " 'ruthful',\n",
       " 'technologies',\n",
       " 'finance',\n",
       " 'sucks',\n",
       " 'side',\n",
       " '08719839835',\n",
       " 'unknown',\n",
       " 'dint',\n",
       " 'bin',\n",
       " 'hsbc',\n",
       " 'january',\n",
       " 'deer',\n",
       " 'kit',\n",
       " 'wrongly',\n",
       " 'tablets',\n",
       " 'difficulties',\n",
       " '2go',\n",
       " 'ext',\n",
       " 'tlp',\n",
       " 'close',\n",
       " 'dental',\n",
       " '2lands',\n",
       " 'sense',\n",
       " 'fuuuuck',\n",
       " 'stomach',\n",
       " 'knees',\n",
       " 'fixes',\n",
       " 'vehicle',\n",
       " 'probthat',\n",
       " 'combination',\n",
       " 'loko',\n",
       " 'broth',\n",
       " 'aren',\n",
       " 'info',\n",
       " 'engagement',\n",
       " 'sunday',\n",
       " 'who',\n",
       " 'tis',\n",
       " 'halloween',\n",
       " 'havin',\n",
       " 'ugadi',\n",
       " 'water',\n",
       " '21st',\n",
       " 'recognises',\n",
       " 'raining',\n",
       " 'flag',\n",
       " '08715203677',\n",
       " 'outreach',\n",
       " 'nattil',\n",
       " 'unni',\n",
       " 'sudn',\n",
       " 'format',\n",
       " 'beers',\n",
       " 'motivating',\n",
       " 'rush',\n",
       " 'prakasamanu',\n",
       " '820554ad0a1705572711',\n",
       " 'port',\n",
       " 'prasad',\n",
       " 'aunts',\n",
       " 'frndshp',\n",
       " 'demand',\n",
       " 'drugdealer',\n",
       " 'movietrivia',\n",
       " 'explain',\n",
       " 'history',\n",
       " 'paru',\n",
       " 'shakespeare',\n",
       " 'truth',\n",
       " 'ip',\n",
       " 'fastest',\n",
       " 'plans',\n",
       " 'chosen',\n",
       " 'we',\n",
       " 'slices',\n",
       " 'cars',\n",
       " 'art',\n",
       " 'kissing',\n",
       " 'splleing',\n",
       " 'cut',\n",
       " 'anywhere',\n",
       " 'pg',\n",
       " 'onam',\n",
       " 'cusoon',\n",
       " 'aging',\n",
       " 'fated',\n",
       " 'wahala',\n",
       " 'up',\n",
       " 'cheyyamo',\n",
       " 'widelive',\n",
       " 'wrld',\n",
       " 'familiar',\n",
       " 'married',\n",
       " 'bak',\n",
       " 'gonna',\n",
       " 'reltnship',\n",
       " '449071512431',\n",
       " 'hop',\n",
       " 'movie',\n",
       " 'clarify',\n",
       " 'easier',\n",
       " 'kind',\n",
       " 'exmpel',\n",
       " 'roller',\n",
       " 'world',\n",
       " 'shame',\n",
       " 'iz',\n",
       " 'etc',\n",
       " '69988',\n",
       " 'selflessness',\n",
       " 'newspapers',\n",
       " 'stress',\n",
       " 'yr',\n",
       " 'crossing',\n",
       " 'inviting',\n",
       " 'age16',\n",
       " 'buy',\n",
       " 'crisis',\n",
       " 'gautham',\n",
       " 'reaching',\n",
       " 'ruin',\n",
       " 'callertune',\n",
       " 'showers',\n",
       " 'good',\n",
       " 'see',\n",
       " 'velusamy',\n",
       " 'dps',\n",
       " 'victoria',\n",
       " 'cashto',\n",
       " 'haiyoh',\n",
       " 'reasons',\n",
       " 'parked',\n",
       " 'happier',\n",
       " '08715205273',\n",
       " 'module',\n",
       " 'payment',\n",
       " '9t',\n",
       " '3mobile',\n",
       " '5000',\n",
       " '150pw',\n",
       " 'educational',\n",
       " 'la',\n",
       " 'something',\n",
       " 'shortage',\n",
       " '515',\n",
       " 'craving',\n",
       " 'bare',\n",
       " 'played',\n",
       " 'they',\n",
       " 'gender',\n",
       " 'hunks',\n",
       " 'put',\n",
       " 'dance',\n",
       " 'teresa',\n",
       " 'tomorro',\n",
       " 'rd',\n",
       " 'tacos',\n",
       " 'wife',\n",
       " 'satisfied',\n",
       " '6times',\n",
       " 'dabbles',\n",
       " 'evening',\n",
       " 'tolerat',\n",
       " 'tag',\n",
       " '2stoptx',\n",
       " 'cheat',\n",
       " '08712101358',\n",
       " 'epi',\n",
       " 'meow',\n",
       " 'junna',\n",
       " 'mymoby',\n",
       " 'mindset',\n",
       " 'charge',\n",
       " 'effects',\n",
       " 'spoiled',\n",
       " 'again',\n",
       " 'customer',\n",
       " 'reserved',\n",
       " 'hole',\n",
       " 'stayed',\n",
       " 'ringtoneking',\n",
       " 'cause',\n",
       " 'bend',\n",
       " '08702840625',\n",
       " 'oreos',\n",
       " 'nipost',\n",
       " 'jesus',\n",
       " 'erutupalam',\n",
       " '449050000301',\n",
       " 'xclusive',\n",
       " 'kay',\n",
       " 'carpark',\n",
       " 'grab',\n",
       " 'fudge',\n",
       " 'evey',\n",
       " 'themes',\n",
       " 'fab',\n",
       " 'med',\n",
       " 'tayseer',\n",
       " 'cbe',\n",
       " 'wnt',\n",
       " 'urself',\n",
       " 'repair',\n",
       " 'veggie',\n",
       " 'freefone',\n",
       " 'present',\n",
       " 'round',\n",
       " 'chad',\n",
       " 'public',\n",
       " '6hl',\n",
       " 'seeking',\n",
       " 'tellmiss',\n",
       " 'heal',\n",
       " 'belly',\n",
       " 'ovarian',\n",
       " 'idew',\n",
       " 'occasion',\n",
       " 'ji',\n",
       " 'uptown',\n",
       " 'hav',\n",
       " 'pockets',\n",
       " 'alert',\n",
       " 'golden',\n",
       " 'ability',\n",
       " 'dl',\n",
       " 'forward',\n",
       " 'hills',\n",
       " 'nigh',\n",
       " 'sends',\n",
       " 'ring',\n",
       " 'carryin',\n",
       " 'skateboarding',\n",
       " 'else',\n",
       " 'asks',\n",
       " 'twittering',\n",
       " 'truffles',\n",
       " '4years',\n",
       " 'further',\n",
       " 'topic',\n",
       " 'returned',\n",
       " 'tiz',\n",
       " 'files',\n",
       " 'sch',\n",
       " 'seing',\n",
       " '81010',\n",
       " 'holiday',\n",
       " 'nobody',\n",
       " 'yaxxx',\n",
       " 'interesting',\n",
       " 'fifty',\n",
       " 'mark',\n",
       " 'flew',\n",
       " 'pages',\n",
       " 'adi',\n",
       " 'gr8',\n",
       " 'st',\n",
       " 'onbus',\n",
       " 'availa',\n",
       " 'shitin',\n",
       " 'dessert',\n",
       " 'basketball',\n",
       " '08081263000',\n",
       " 'q',\n",
       " 'fan',\n",
       " '40mph',\n",
       " 'matthew',\n",
       " 'happend',\n",
       " 'smiley',\n",
       " 'action',\n",
       " 'refund',\n",
       " 'pounded',\n",
       " 'process',\n",
       " 'canary',\n",
       " 'w1j',\n",
       " '5k',\n",
       " 'kalaachutaarama',\n",
       " 'whom',\n",
       " 'unclaimed',\n",
       " 'whatsup',\n",
       " 'worms',\n",
       " 'howu',\n",
       " 'uup',\n",
       " 'sentiment',\n",
       " 'spent',\n",
       " 'mouth',\n",
       " 'gm',\n",
       " 'invnted',\n",
       " 'ex',\n",
       " 'biggest',\n",
       " 'fucked',\n",
       " 'stop2stop',\n",
       " 'mcr',\n",
       " 'ducking',\n",
       " 'missin',\n",
       " 'd3wv',\n",
       " 'apes',\n",
       " 'place',\n",
       " 'rule',\n",
       " 'costume',\n",
       " 'squeeeeeze',\n",
       " 'sptv',\n",
       " 'jackson',\n",
       " 'tariffs',\n",
       " 'wating',\n",
       " 'gray',\n",
       " 'may',\n",
       " 'she',\n",
       " 'dates',\n",
       " 'monkeespeople',\n",
       " 'okmail',\n",
       " 'barbie',\n",
       " 'recharged',\n",
       " 'dem',\n",
       " 'm8s',\n",
       " 'diamonds',\n",
       " 'literally',\n",
       " 'worc',\n",
       " 'afraid',\n",
       " '41782',\n",
       " 'ifink',\n",
       " 'ben',\n",
       " 'norm150p',\n",
       " 'praps',\n",
       " 'childish',\n",
       " 'daytime',\n",
       " 'anjola',\n",
       " 'nuerologist',\n",
       " '530',\n",
       " 'ouch',\n",
       " 'eng',\n",
       " 'cs',\n",
       " 'b4utele',\n",
       " 'croydon',\n",
       " 'split',\n",
       " 'symptoms',\n",
       " 'brandy',\n",
       " 'minmobsmorelkpobox177hp51fl',\n",
       " 'respectful',\n",
       " 'contents',\n",
       " 'vodka',\n",
       " 'objection',\n",
       " 'gist',\n",
       " '140ppm',\n",
       " 'ryan',\n",
       " 'surya',\n",
       " 'sup',\n",
       " 'atleast',\n",
       " 'suitemates',\n",
       " 'cds',\n",
       " 'spys',\n",
       " '946',\n",
       " 'allo',\n",
       " 'upto',\n",
       " 'lap',\n",
       " 'cost',\n",
       " 'leadership',\n",
       " 'wahleykkum',\n",
       " '150p16',\n",
       " 'faggy',\n",
       " 'hurried',\n",
       " 'iwana',\n",
       " 'kothi',\n",
       " 'comuk',\n",
       " 'go2',\n",
       " 'cooking',\n",
       " 'images',\n",
       " 'lotr',\n",
       " 'noncomittal',\n",
       " 'invention',\n",
       " 'needing',\n",
       " 'ok',\n",
       " '2geva',\n",
       " 'blogspot',\n",
       " 'sittin',\n",
       " 'ciao',\n",
       " 'phrase',\n",
       " 'dolls',\n",
       " 'pudunga',\n",
       " 'century',\n",
       " 'wouldn',\n",
       " 'pence',\n",
       " 'dan',\n",
       " 'issues',\n",
       " 'grahmbell',\n",
       " 'tool',\n",
       " 'box385',\n",
       " 'fgkslpo',\n",
       " 'speed',\n",
       " 'syria',\n",
       " 'freak',\n",
       " 'edition',\n",
       " 'lotsof',\n",
       " 'goodfriend',\n",
       " 'cthen',\n",
       " 'street',\n",
       " 'frnds',\n",
       " 'private',\n",
       " 'lyk',\n",
       " 'did',\n",
       " '09058097218',\n",
       " 'temp',\n",
       " 'lucy',\n",
       " 'recycling',\n",
       " 'bras',\n",
       " 'cheaper',\n",
       " 'reading',\n",
       " 'hitler',\n",
       " 'addamsfa',\n",
       " 'constant',\n",
       " 'mandara',\n",
       " 'linerental',\n",
       " 'tim',\n",
       " 'sam',\n",
       " 'slots',\n",
       " 'uworld',\n",
       " 'mids',\n",
       " 'useful',\n",
       " 'illspeak',\n",
       " 'listen',\n",
       " 'tahan',\n",
       " 'bergkamp',\n",
       " 'hangin',\n",
       " 'station',\n",
       " 'l8tr',\n",
       " 'class',\n",
       " '0845',\n",
       " 'queen',\n",
       " 'card',\n",
       " '86888',\n",
       " 'lab',\n",
       " 'vday',\n",
       " 'outgoing',\n",
       " '08717205546',\n",
       " 'srs',\n",
       " 'transaction',\n",
       " 'listener',\n",
       " 'tarot',\n",
       " 'spanish',\n",
       " 'bunkers',\n",
       " 'upd8',\n",
       " 'muz',\n",
       " 'avoid',\n",
       " 'check',\n",
       " 'repeating',\n",
       " 'balloon',\n",
       " '87021',\n",
       " 'unintentionally',\n",
       " 'shiny',\n",
       " 'txting',\n",
       " 'hg',\n",
       " 'pendent',\n",
       " 'allday',\n",
       " 'wants',\n",
       " 'yifeng',\n",
       " 'chess',\n",
       " 'or',\n",
       " 'sooner',\n",
       " 'ibm',\n",
       " 'impression',\n",
       " 'freshers',\n",
       " 'gate',\n",
       " 'help08714742804',\n",
       " 'arab',\n",
       " 'dressed',\n",
       " 'university',\n",
       " 'multis',\n",
       " 'sday',\n",
       " 'normal',\n",
       " 'thriller',\n",
       " 'yrs',\n",
       " 'free',\n",
       " 'later',\n",
       " 'because',\n",
       " 'festival',\n",
       " 'massive',\n",
       " 'hairdressers',\n",
       " 'steam',\n",
       " 'kid',\n",
       " 'best1',\n",
       " 'woohoo',\n",
       " 'instead',\n",
       " '6hrs',\n",
       " 'make',\n",
       " 'virtual',\n",
       " 'temple',\n",
       " '09050005321',\n",
       " '2morrow',\n",
       " '6zf',\n",
       " 'mt',\n",
       " 'sick',\n",
       " 'properly',\n",
       " '6230',\n",
       " 'kerala',\n",
       " 'slice',\n",
       " 'ente',\n",
       " 'what',\n",
       " 'disc',\n",
       " 'hits',\n",
       " '7250',\n",
       " 'ghodbandar',\n",
       " 'added',\n",
       " 'fran',\n",
       " 'logged',\n",
       " 'says',\n",
       " 'lover',\n",
       " '125gift',\n",
       " 'quoting',\n",
       " 'buyer',\n",
       " 'ld',\n",
       " 'urawinner',\n",
       " 'do',\n",
       " 'excuses',\n",
       " 'cum',\n",
       " 'browser',\n",
       " 'travel',\n",
       " 'oveable',\n",
       " 'her',\n",
       " 'keeping',\n",
       " 'attended',\n",
       " 'sleeps',\n",
       " 'rec',\n",
       " 'sign',\n",
       " 'stay',\n",
       " 'dancin',\n",
       " 'beggar',\n",
       " '2exit',\n",
       " 'fakeye',\n",
       " 'difference',\n",
       " 'worry',\n",
       " 'ful',\n",
       " 'caring',\n",
       " 'noisy',\n",
       " 'gift',\n",
       " 'iq',\n",
       " 'stifled',\n",
       " 'bathing',\n",
       " 'elephant',\n",
       " 'hypertension',\n",
       " 'textoperator',\n",
       " 'phoenix',\n",
       " 'care',\n",
       " 'yan',\n",
       " 'x2',\n",
       " 'frmcloud',\n",
       " 'nope',\n",
       " 'thus',\n",
       " 'caroline',\n",
       " 'enjoyin',\n",
       " 'how',\n",
       " 'theres',\n",
       " 'representative',\n",
       " 'babygoodbye',\n",
       " 'were',\n",
       " 'sry',\n",
       " 'rstm',\n",
       " '153',\n",
       " 'billed',\n",
       " 'puttin',\n",
       " 'elama',\n",
       " 'dialling',\n",
       " 'hooch',\n",
       " 'omg',\n",
       " 'indian',\n",
       " '09066358152',\n",
       " 'truro',\n",
       " 'left',\n",
       " 'qi',\n",
       " 'eek',\n",
       " 'phews',\n",
       " 'pushbutton',\n",
       " 'happens',\n",
       " 'rencontre',\n",
       " 'steering',\n",
       " '09099725823',\n",
       " 'cnl',\n",
       " 'determined',\n",
       " 'sighs',\n",
       " 'presence',\n",
       " 'stopsms',\n",
       " 'shola',\n",
       " 'cutting',\n",
       " 'embarassing',\n",
       " 'shoving',\n",
       " 'msgrcvd18',\n",
       " 'nmde',\n",
       " 'num',\n",
       " 'definitly',\n",
       " 'masked',\n",
       " 'il',\n",
       " 'ya',\n",
       " '08719181513',\n",
       " 'spacebucks',\n",
       " 'starve',\n",
       " 'feels',\n",
       " 'network',\n",
       " 'error',\n",
       " 'want',\n",
       " 'beautiful',\n",
       " 'nearby',\n",
       " 'huai',\n",
       " 'unconvinced',\n",
       " 'vodafone',\n",
       " 'sunroof',\n",
       " 'wildest',\n",
       " 'teletext',\n",
       " 'box97n7qp',\n",
       " 'dearer',\n",
       " 'trebles',\n",
       " 'rent',\n",
       " 'includes',\n",
       " 'hai',\n",
       " 'clearly',\n",
       " 'shouted',\n",
       " 'spk',\n",
       " 'woould',\n",
       " 'moving',\n",
       " 'songs',\n",
       " 'surely',\n",
       " 'you',\n",
       " 'wednesday',\n",
       " 'talents',\n",
       " 'avoiding',\n",
       " 'le',\n",
       " 'valentine',\n",
       " 'shared',\n",
       " '30',\n",
       " 'quality',\n",
       " 'die',\n",
       " 'read',\n",
       " 'whats',\n",
       " 'longer',\n",
       " 'merely',\n",
       " 'tessy',\n",
       " ...]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['SMS'] = train['SMS'].str.split()\n",
    "vocabulary = []\n",
    "for i in train['SMS']:\n",
    "    for j in i:\n",
    "        vocabulary.append(j)\n",
    "        \n",
    "vocabulary = set(vocabulary) #to remove any duplicated terms\n",
    "vocabulary = list(vocabulary) #convert back to list\n",
    "vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count_per_sms = {}\n",
    "for unique_word in vocabulary:\n",
    "    word_count_per_sms[unique_word] = [0] * len(train)\n",
    "train = train.reset_index(drop=True)\n",
    "for index, msg in enumerate(train['SMS']):\n",
    "    for word in msg:\n",
    "        word_count_per_sms[word][index] += 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000pes</th>\n",
       "      <th>008704050406</th>\n",
       "      <th>0089</th>\n",
       "      <th>01223585334</th>\n",
       "      <th>02</th>\n",
       "      <th>0207</th>\n",
       "      <th>02072069400</th>\n",
       "      <th>...</th>\n",
       "      <th>zindgi</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zogtorius</th>\n",
       "      <th>zouk</th>\n",
       "      <th>zyada</th>\n",
       "      <th>é</th>\n",
       "      <th>ú1</th>\n",
       "      <th>ü</th>\n",
       "      <th>〨ud</th>\n",
       "      <th>鈥</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7783 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  00  000  000pes  008704050406  0089  01223585334  02  0207  02072069400  \\\n",
       "0  0   0    0       0             0     0            0   0     0            0   \n",
       "1  0   0    0       0             0     0            0   0     0            0   \n",
       "2  0   0    0       0             0     0            0   0     0            0   \n",
       "3  0   0    0       0             0     0            0   0     0            0   \n",
       "4  0   0    0       0             0     0            0   0     0            0   \n",
       "\n",
       "  ...  zindgi  zoe  zogtorius  zouk  zyada  é  ú1  ü  〨ud  鈥  \n",
       "0 ...       0    0          0     0      0  0   0  0    0  0  \n",
       "1 ...       0    0          0     0      0  0   0  0    0  0  \n",
       "2 ...       0    0          0     0      0  0   0  0    0  0  \n",
       "3 ...       0    0          0     0      0  0   0  0    0  0  \n",
       "4 ...       0    0          0     0      0  0   0  2    0  0  \n",
       "\n",
       "[5 rows x 7783 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts = pd.DataFrame(word_count_per_sms)\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#concatenate word_count dataframe with training dataframe\n",
    "train_set_clean = pd.concat([train, word_counts], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>0</th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000pes</th>\n",
       "      <th>008704050406</th>\n",
       "      <th>0089</th>\n",
       "      <th>01223585334</th>\n",
       "      <th>02</th>\n",
       "      <th>...</th>\n",
       "      <th>zindgi</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zogtorius</th>\n",
       "      <th>zouk</th>\n",
       "      <th>zyada</th>\n",
       "      <th>é</th>\n",
       "      <th>ú1</th>\n",
       "      <th>ü</th>\n",
       "      <th>〨ud</th>\n",
       "      <th>鈥</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yep, by, the, pretty, sculpture]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yes, princess, are, you, going, to, make, me,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>[welp, apparently, he, retired]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[havent]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[i, forgot, 2, ask, ü, all, smth, there, s, a,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS  0  00  000  \\\n",
       "0   ham                  [yep, by, the, pretty, sculpture]  0   0    0   \n",
       "1   ham  [yes, princess, are, you, going, to, make, me,...  0   0    0   \n",
       "2   ham                    [welp, apparently, he, retired]  0   0    0   \n",
       "3   ham                                           [havent]  0   0    0   \n",
       "4   ham  [i, forgot, 2, ask, ü, all, smth, there, s, a,...  0   0    0   \n",
       "\n",
       "   000pes  008704050406  0089  01223585334  02 ...  zindgi  zoe  zogtorius  \\\n",
       "0       0             0     0            0   0 ...       0    0          0   \n",
       "1       0             0     0            0   0 ...       0    0          0   \n",
       "2       0             0     0            0   0 ...       0    0          0   \n",
       "3       0             0     0            0   0 ...       0    0          0   \n",
       "4       0             0     0            0   0 ...       0    0          0   \n",
       "\n",
       "   zouk  zyada  é  ú1  ü  〨ud  鈥  \n",
       "0     0      0  0   0  0    0  0  \n",
       "1     0      0  0   0  0    0  0  \n",
       "2     0      0  0   0  0    0  0  \n",
       "3     0      0  0   0  0    0  0  \n",
       "4     0      0  0   0  2    0  0  \n",
       "\n",
       "[5 rows x 7785 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_set_clean.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll first start by calculating common probabilities - p_spam and p_ham. We will also calculate n_ham(number of words in all ham messages), n_spam and n_vocabulary. These terms are common in all probability equations. We will also initiate the smoothing filter to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_ham = 0.8654104979811574\n",
      "p_spam = 0.13458950201884254\n"
     ]
    }
   ],
   "source": [
    "ham_df = train_set_clean[train_set_clean['Label'] == 'ham']\n",
    "spam_df = train_set_clean[train_set_clean['Label'] == 'spam']\n",
    "p_ham = len(ham_df) / len(train_set_clean)\n",
    "p_spam = len(spam_df) / len(train_set_clean)\n",
    "print('p_ham = {}' .format(p_ham))\n",
    "print('p_spam = {}' .format(p_spam))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_ham = 57237\n",
      "n_spam = 15190\n",
      "n_vocabulary = 7783\n"
     ]
    }
   ],
   "source": [
    "n_ham = 0\n",
    "for row in ham_df['SMS']:\n",
    "    n_ham += len(row)\n",
    "    \n",
    "n_spam = 0\n",
    "for row in spam_df['SMS']:\n",
    "    n_spam += len(row)\n",
    "n_vocabulary = len(vocabulary) \n",
    "alpha = 1\n",
    "print('n_ham = {}' .format(n_ham))\n",
    "print('n_spam = {}' .format(n_spam))\n",
    "print('n_vocabulary = {}' .format(n_vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize probabilities\n",
    "p_word_given_spam = {}\n",
    "p_word_given_ham = {}\n",
    "for word in vocabulary:\n",
    "    p_word_given_ham[word] = 0\n",
    "    p_word_given_spam[word] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in vocabulary:\n",
    "    ham_word = 0\n",
    "    spam_word = 0\n",
    "    for sms in ham_df['SMS']:\n",
    "        ham_word += sum([i == word for i in sms])\n",
    "    p_word_given_ham[word] = (ham_word + alpha) / (n_ham + alpha*n_vocabulary)\n",
    "    for sms in spam_df['SMS']:\n",
    "        spam_word += sum([i == word for i in sms])\n",
    "    p_word_given_spam[word] = (spam_word + alpha) / (n_spam + alpha*n_vocabulary)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00039987696093509687"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_word_given_ham['forgot']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have calculated all the probabilities associated with Naive Bayes Theorem. Now we will write a function to classify any incoming new message as spam or ham."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def classify(message):\n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "    #print(message)\n",
    "    #initiale probabilities\n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "    #print(p_spam_given_message)\n",
    "    #print(p_ham_given_message)\n",
    "    \n",
    "    #loop through the message and multiply probabilities of each word\n",
    "    for word in message:\n",
    "        if word in vocabulary:\n",
    "            p_spam_given_message *= p_word_given_spam[word]\n",
    "            p_ham_given_message *= p_word_given_ham[word]\n",
    "    print(p_spam_given_message)\n",
    "    print(p_ham_given_message)\n",
    "    if p_spam_given_message > p_ham_given_message:\n",
    "        print('Label: Spam')\n",
    "    elif p_ham_given_message > p_spam_given_message:\n",
    "        print('Label: Ham')\n",
    "    else:\n",
    "        print('Equal probabilities, have a human classify this!')\n",
    "    return\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.43136700206982e-18\n",
      "2.824167598198773e-14\n",
      "Label: Ham\n"
     ]
    }
   ],
   "source": [
    "classify('Sounds, good, Neha. See u there - Adarsh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3481290211300841e-25\n",
      "1.9368049028589875e-27\n",
      "Label: Spam\n"
     ]
    }
   ],
   "source": [
    "classify('WINNER!! This is the secret code to unlock the money: C3421')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "After testing the classify function on two example messages, we will test the accuracy of the spam filter by testing it on the test set. We will modify the classify function to return the label instead of printing which we will save in a new column in our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify_test_set(message):\n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "    #print(message)\n",
    "    #initiale probabilities\n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "    #print(p_spam_given_message)\n",
    "    #print(p_ham_given_message)\n",
    "    \n",
    "    #loop through the message and multiply probabilities of each word\n",
    "    for word in message:\n",
    "        if word in vocabulary:\n",
    "            p_spam_given_message *= p_word_given_spam[word]\n",
    "            p_ham_given_message *= p_word_given_ham[word]\n",
    "    #print(p_spam_given_message)\n",
    "    #print(p_ham_given_message)\n",
    "    if p_spam_given_message > p_ham_given_message:\n",
    "        classification = 'spam'\n",
    "    elif p_ham_given_message > p_spam_given_message:\n",
    "        classification = 'ham'\n",
    "    else:\n",
    "        classification = 'Equal probabilities, have a human classify this!'\n",
    "    return classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dataquest/system/env/python3/lib/python3.4/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2131</th>\n",
       "      <td>ham</td>\n",
       "      <td>Later i guess. I needa do mcat study too.</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3418</th>\n",
       "      <td>ham</td>\n",
       "      <td>But i haf enuff space got like 4 mb...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3424</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 10 mths? Update to latest Oran...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1538</th>\n",
       "      <td>ham</td>\n",
       "      <td>All sounds good. Fingers . Makes it difficult ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5393</th>\n",
       "      <td>ham</td>\n",
       "      <td>All done, all handed in. Don't know if mega sh...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                                SMS predicted\n",
       "2131   ham          Later i guess. I needa do mcat study too.       ham\n",
       "3418   ham             But i haf enuff space got like 4 mb...       ham\n",
       "3424  spam  Had your mobile 10 mths? Update to latest Oran...      spam\n",
       "1538   ham  All sounds good. Fingers . Makes it difficult ...       ham\n",
       "5393   ham  All done, all handed in. Don't know if mega sh...       ham"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test['predicted'] = test['SMS'].apply(classify_test_set)\n",
    "display(test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now measure the accuracy of our spam filter, where -\n",
    "\n",
    "\\begin{equation}\n",
    "Accuracy = \\frac {number\\ of\\ correctly\\ classified\\ messages}{total\\ number\\ of\\ classified\\ messages}\n",
    "\\end{equation}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.74326750448833"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "correct = sum(test['Label'] == test['predicted']) \n",
    "total = len(test)\n",
    "accuracy = correct / total\n",
    "display(accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of our Naive Bayes spam filter is 98.743268%\n"
     ]
    }
   ],
   "source": [
    "print('The accuracy of our Naive Bayes spam filter is {:3f}%' .format(accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
